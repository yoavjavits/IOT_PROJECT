{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Device id  0  -  Microsoft Sound Mapper - Input\n",
      "Input Device id  1  -  Microphone Array (טכנולוגיית In\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.ops import gen_audio_ops as audio_ops\n",
    "from datetime import datetime\n",
    "\n",
    "model = keras.models.load_model(\"fully_trained.model\")\n",
    "\n",
    "FORMAT = pyaudio.paFloat32\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "NOFFRAMES = 8000\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "info = audio.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "for i in range(0, numdevices):\n",
    "    if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "        print(\"Input Device id \", i, \" - \",\n",
    "              audio.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
    "\n",
    "\n",
    "samples = np.zeros((8000))\n",
    "\n",
    "\n",
    "def callback(input_data, frame_count, time_info, flags):\n",
    "    global samples\n",
    "    # print(\"Got audio \" + str(frame_count))\n",
    "    new_samples = np.frombuffer(input_data, np.float32)\n",
    "    samples = np.concatenate((samples, new_samples))\n",
    "    samples = samples[-16000:]\n",
    "\n",
    "    if len(samples) == 16000:\n",
    "        start = time.perf_counter()\n",
    "        # normalise the samples\n",
    "        normalised = samples - np.mean(samples)\n",
    "        max = np.max(normalised)\n",
    "        if max > 0:\n",
    "            normalised = normalised / max\n",
    "\n",
    "        # create the spectrogram\n",
    "        spectrogram = audio_ops.audio_spectrogram(\n",
    "            np.reshape(normalised, (16000, 1)),\n",
    "            window_size=320,\n",
    "            stride=160, \n",
    "            magnitude_squared=True)\n",
    "        # reduce the number of frequency bins in our spectrogram to a more sensible level\n",
    "        spectrogram = tf.nn.pool(\n",
    "            input=tf.expand_dims(spectrogram, -1),\n",
    "            window_shape=[1, 6],\n",
    "            strides=[1, 6],\n",
    "            pooling_type='AVG',\n",
    "            padding='SAME')\n",
    "        # remove the first 1 index\n",
    "        spectrogram = tf.squeeze(spectrogram, axis=0)\n",
    "        spectrogram = np.log10(spectrogram + 1e-6)\n",
    "        prediction = model.predict(np.reshape(spectrogram, (1, 99, 43, 1)))        \n",
    "        \n",
    "        index = 0\n",
    "        max_value = 0\n",
    "        for i in range(4):\n",
    "            if prediction[0][i] > max_value:\n",
    "                max_value = prediction[0][i]\n",
    "                index = i\n",
    "        \n",
    "        dict_predict = {0 : 'backward', 1: 'right', 2:'down', 3:'invalid'}        \n",
    "        if max_value > 0.95 and index != 3:\n",
    "            print(\n",
    "                f\"{datetime.now().time()} - {dict_predict[index]}, and score: {max_value}\")\n",
    "        \n",
    "        end = time.perf_counter()\n",
    "        # print((end-start)*1000)\n",
    "\n",
    "    return input_data, pyaudio.paContinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak\n",
      "18:59:25.140162 - down, and score: 0.9933440685272217\n",
      "18:59:40.642372 - backward, and score: 0.9989527463912964\n",
      "18:59:41.143186 - backward, and score: 0.9988227486610413\n",
      "18:59:49.237519 - backward, and score: 0.9863978028297424\n",
      "18:59:56.141917 - right, and score: 0.9874160885810852\n",
      "19:00:08.142313 - backward, and score: 0.9566164612770081\n",
      "19:00:11.132846 - right, and score: 0.9985013008117676\n",
      "19:00:11.642252 - right, and score: 0.9999924898147583\n",
      "19:00:13.139917 - right, and score: 0.9999488592147827\n",
      "19:00:23.151297 - down, and score: 0.9746382236480713\n",
      "19:00:28.140886 - backward, and score: 0.9623441696166992\n",
      "19:00:30.148737 - right, and score: 0.9973684549331665\n",
      "19:00:44.639720 - backward, and score: 0.9685735106468201\n",
      "19:01:02.639582 - backward, and score: 0.9915940761566162\n",
      "19:01:23.129948 - down, and score: 0.9586398005485535\n",
      "19:01:32.647412 - down, and score: 0.9609899520874023\n",
      "19:02:03.139293 - backward, and score: 0.9804110527038574\n",
      "19:02:46.636075 - backward, and score: 0.988532304763794\n",
      "19:03:04.148411 - backward, and score: 0.9653032422065735\n",
      "19:07:24.636498 - down, and score: 0.9587563276290894\n",
      "19:08:31.150347 - down, and score: 0.9563358426094055\n",
      "19:21:14.228685 - down, and score: 0.9737528562545776\n",
      "19:35:02.137776 - down, and score: 0.9558569192886353\n",
      "19:35:35.636753 - backward, and score: 0.9633296132087708\n",
      "19:35:50.627168 - backward, and score: 0.9586370587348938\n"
     ]
    }
   ],
   "source": [
    "stream = audio.open(\n",
    "    input_device_index=0,\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    stream_callback=callback,\n",
    "    frames_per_buffer=NOFFRAMES)\n",
    "\n",
    "stream.start_stream()\n",
    "print(\"speak\")\n",
    "\n",
    "# wait for stream to finish (5)\n",
    "while stream.is_active() and time.time:\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream.stop_stream()\n",
    "# stream.close()\n",
    "# p.terminate()\n",
    "# print('done')\n",
    "# plt.plot(decoded)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7fb1200cdbce936b89092ce41e5d7335b36a1df3306eb52694f72a51452b86b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
