{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Device id  0  -  Microsoft Sound Mapper - Input\n",
      "Input Device id  1  -  Microphone Array (טכנולוגיית In\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.ops import gen_audio_ops as audio_ops\n",
    "from datetime import datetime\n",
    "\n",
    "model = keras.models.load_model(\"fully_trained.model\")\n",
    "\n",
    "FORMAT = pyaudio.paFloat32\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "NOFFRAMES = 8000\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "info = audio.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "for i in range(0, numdevices):\n",
    "    if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "        print(\"Input Device id \", i, \" - \",\n",
    "              audio.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
    "\n",
    "\n",
    "samples = np.zeros((8000))\n",
    "\n",
    "\n",
    "def callback(input_data, frame_count, time_info, flags):\n",
    "    global samples\n",
    "    # print(\"Got audio \" + str(frame_count))\n",
    "    new_samples = np.frombuffer(input_data, np.float32)\n",
    "    samples = np.concatenate((samples, new_samples))\n",
    "    samples = samples[-16000:]\n",
    "\n",
    "    if len(samples) == 16000:\n",
    "        start = time.perf_counter()\n",
    "        # normalise the samples\n",
    "        normalised = samples - np.mean(samples)\n",
    "        max = np.max(normalised)\n",
    "        if max > 0:\n",
    "            normalised = normalised / max\n",
    "\n",
    "        # create the spectrogram\n",
    "        spectrogram = audio_ops.audio_spectrogram(\n",
    "            np.reshape(normalised, (16000, 1)),\n",
    "            window_size=320,\n",
    "            stride=160, \n",
    "            magnitude_squared=True)\n",
    "        # reduce the number of frequency bins in our spectrogram to a more sensible level\n",
    "        spectrogram = tf.nn.pool(\n",
    "            input=tf.expand_dims(spectrogram, -1),\n",
    "            window_shape=[1, 6],\n",
    "            strides=[1, 6],\n",
    "            pooling_type='AVG',\n",
    "            padding='SAME')\n",
    "        # remove the first 1 index\n",
    "        spectrogram = tf.squeeze(spectrogram, axis=0)\n",
    "        spectrogram = np.log10(spectrogram + 1e-6)\n",
    "        prediction = model.predict(np.reshape(spectrogram, (1, 99, 43, 1)))        \n",
    "        \n",
    "        index = 0\n",
    "        max_value = 0\n",
    "        for i in range(7):\n",
    "            if prediction[0][i] > max_value:\n",
    "                max_value = prediction[0][i]\n",
    "                index = i\n",
    "        \n",
    "        dict_predict = {0 : 'forward', 1: 'backward', 2:'left', 3:'right', 4:'one', 5:'zero', 6:'invalid'}        \n",
    "        if max_value > 0.95 and index != 6:\n",
    "            print(\n",
    "                f\"{datetime.now().time()} - {dict_predict[index]}, and score: {max_value}\")\n",
    "        \n",
    "        end = time.perf_counter()\n",
    "        # print((end-start)*1000)\n",
    "\n",
    "    return input_data, pyaudio.paContinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak\n",
      "23:36:59.958387 - right, and score: 0.9834263324737549\n",
      "23:37:05.969395 - backward, and score: 0.9812319874763489\n",
      "23:37:30.462275 - zero, and score: 0.9911172389984131\n",
      "23:37:31.957123 - one, and score: 0.9996234178543091\n",
      "23:37:32.473829 - one, and score: 0.9999568462371826\n",
      "23:37:34.953992 - zero, and score: 0.9978335499763489\n",
      "23:37:39.972665 - zero, and score: 0.9800373315811157\n",
      "23:37:50.476123 - right, and score: 0.9994290471076965\n",
      "23:37:50.965646 - right, and score: 0.9977118968963623\n",
      "23:37:53.961799 - right, and score: 0.9970663189888\n",
      "23:37:54.457929 - right, and score: 0.996692419052124\n",
      "23:38:01.958795 - left, and score: 0.9586244225502014\n",
      "23:38:09.463391 - right, and score: 0.9899896383285522\n",
      "23:38:11.464216 - one, and score: 0.9916074275970459\n",
      "23:38:12.955885 - zero, and score: 0.9843147397041321\n",
      "23:38:17.454766 - backward, and score: 0.9979459643363953\n",
      "23:38:27.953012 - forward, and score: 0.9950396418571472\n",
      "23:38:33.469741 - right, and score: 0.9998117089271545\n",
      "23:38:34.450763 - right, and score: 0.9679785966873169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\javits\\Technion\\IOT_PROJECT_236332\\IOT_PROJECT\\Software\\LearnNetworks_Python\\ForwardBackwardLeftRightOneZero\\test_model.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/javits/Technion/IOT_PROJECT_236332/IOT_PROJECT/Software/LearnNetworks_Python/ForwardBackwardLeftRightOneZero/test_model.ipynb#ch0000001?line=12'>13</a>\u001b[0m \u001b[39m# wait for stream to finish (5)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/javits/Technion/IOT_PROJECT_236332/IOT_PROJECT/Software/LearnNetworks_Python/ForwardBackwardLeftRightOneZero/test_model.ipynb#ch0000001?line=13'>14</a>\u001b[0m \u001b[39mwhile\u001b[39;00m stream\u001b[39m.\u001b[39mis_active() \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/javits/Technion/IOT_PROJECT_236332/IOT_PROJECT/Software/LearnNetworks_Python/ForwardBackwardLeftRightOneZero/test_model.ipynb#ch0000001?line=14'>15</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.1\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stream = audio.open(\n",
    "    input_device_index=0,\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    stream_callback=callback,\n",
    "    frames_per_buffer=NOFFRAMES)\n",
    "\n",
    "stream.start_stream()\n",
    "print(\"speak\")\n",
    "\n",
    "# wait for stream to finish (5)\n",
    "while stream.is_active() and time.time:\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream.stop_stream()\n",
    "# stream.close()\n",
    "# p.terminate()\n",
    "# print('done')\n",
    "# plt.plot(decoded)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7fb1200cdbce936b89092ce41e5d7335b36a1df3306eb52694f72a51452b86b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
